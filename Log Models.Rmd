---
title: "LogReg Modeling"
author: "Adam Canton"
date: "7/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(dplyr)
library(tidyverse)
library(olsrr)
library(ggplot2)
library(ggcorrplot)
library(GGally)
library(naniar)
library(reshape2)
library(ggthemes)
library(cowplot)
library(aod)
library(ROCR)
library(MASS)
library(caret)
library(e1071)
library(glmnet)
library(ROCR)
library(forcats)
library(car)
```


```{r}
# Grab the file Bank Additional Full - Fill in your file
BankAF <- read.csv(file = "F:/R For Real/Stats-2-Project-2/bank-additional-full.csv", sep = ";", header = TRUE)

# removing obs 36044 - was a large outlier due to a few things: Had previous success, was on the call for an hour, emp rate was low, and nr employed was low
# still a no answer
BankAF <- BankAF[-36044,]

# Change the name of the response from y to Subscription
names(BankAF)[21] <- "Subscription"

# SubNum 1:yes 0:no
BankAF <- BankAF %>% mutate(SubNum = ifelse(Subscription == "yes",1,0))

# Creating an ID column to spot check train test set data - if you have removed observation 36044 then set the sequence to 41187, otherwise 41188
ID <- seq(1,41187,1)
BankAF <- cbind(BankAF, ID)

# the reduced data set below is used for finding interactions terms
#BankAF.Reduced <- BankAF %>% dplyr::select(duration, job, poutcome,education, month, euribor3m, emp.var.rate, cons.price.idx, nr.employed, Subscription)
```

Feature Additions -  None proved useful
```{r}
# Adding some features ---- 
# None of these features proved to be significant adding them in will mess up columns later on
## changing some continous into categoricals
### Pdays - categorical contacted before - 1: yes 0: no
BankAF <- BankAF %>% mutate(PreviousContact = ifelse(pdays == 999, 0,1))
BankAF$PreviousContact <- as.factor(BankAF$PreviousContact)

### Workforce -  1: yes, 0: no (retired, student, unemployed)
BankAF$Workforce <- fct_collapse(BankAF$job,
                                 "1" = c("admin.","blue-collar","entrepreneur","housemaid","management","self-employed","services","technician","unknown"),
                                 "0" = c("student", "retired", "unemployed"))

### Have they had a previous success with this client
BankAF$PreviousSuccess <- fct_collapse(BankAF$poutcome, "1" = c("success"), "0" = c("nonexistent", "failure"))

BankAF$default <- fct_collapse(BankAF$default, "no" = c("unknown", "no"), "yes" = c("yes"))
```

# Logit Models
## Set Training and Test Sets
```{r}
# Create Train and Test sets ----

# How Many yes and no?
DimYes <- 3000 
DimNo <- 3000

# Going to try to create 2 data sets, one for Subscription-yes one for Subscription-no, Sample each one proportionally then recombine into train and test sets
BankAF.yes <- subset(BankAF, Subscription == "yes")
BankAF.no <- subset(BankAF, Subscription == "no")

set.seed(35)
index.yes<-sample(1:dim(BankAF.yes)[1],DimYes,replace=F)
train.yes<-BankAF.yes[index.yes,]
test.yes<-BankAF.yes[-index.yes,]

index.no<-sample(1:dim(BankAF.no)[1],DimNo,replace=F)
train.no<-BankAF.no[index.no,]
test.no<-BankAF.no[-index.no,]

BankAF.train <- rbind(train.no, train.yes)
BankAF.test <- rbind(test.no, test.yes)

# Getting rid of duration  - it will predict nearly perfectly - with this in mean prediction error = 0
# Also have to get rid of ID since it was being selected as good explanatory variable was only added to make sure sampling was working correctly
# add duration here if you wuld like to remove it from the model
BankAF.train = BankAF.train %>% dplyr::select(-c(ID))
BankAF.test = BankAF.test %>% dplyr::select(-c(ID))

# remove intermediate data sets
rm(test.no, test.yes, train.no, train.yes, BankAF.no, BankAF.yes)
```

# Step Model
```{r}
# Creating Step Log model from original variables - full model  75/70
# Subscription ~ (.)^2 looks for significant interactions, only use when reduced data set was sampled
# Subscription ~ ., creates the step models, use with whatever

# if duration is in -22 otherwise -21
full.log <- glm(Subscription ~ ., family = 'binomial', data = BankAF.train[,-c(5,22)])
step.log <- full.log %>% stepAIC(trace = FALSE)

summary(step.log)
# Get predictions from Test set
fit.pred.step <- predict(step.log, newdata = BankAF.test, type= "response")

# look at separation between Yes and No Prediction Probs - this has been somewhat replaced by for loop at the end
# still useful for at a glance viz
p = data.frame(Subs = BankAF.test$Subscription, Preds = fit.pred.step)
names(p)[2] <- 'Preds'
p %>% group_by(Subs, Preds) %>% ggplot(aes(x = Preds, fill = Subs)) + geom_boxplot() + facet_grid(rows = p$Subs)
p.no = p %>% group_by(Subs, Preds) %>% subset(Subs == "no")
summary(p.no)

# Set cutoff for probs 
cutoff.step = 0.35


# Lets see how we did
results.step <- prediction(fit.pred.step,BankAF.test$Subscription,label.ordering=c("no","yes"))

class.step <- factor(ifelse(fit.pred.step > cutoff.step, 'yes','no'),levels = c('no','yes'))

print("Confusion Step")
confusionMatrix(class.step, BankAF.test$Subscription)


# Residuals
plot(step.log)
```

```{r}
# observation 36044 was on the call for a duration of 3509 secs, just short of an hour and still had a no response 
plot(simple.log)

```


# Custom Model - Future Answer to Q2
```{r}
# custom log regression - 61/78
custom.log <- glm(Subscription ~ nr.employed + emp.var.rate + cons.price.idx + euribor3m + poutcome + month + duration*month + duration*poutcome + duration*job,
                  family = "binomial", data = BankAF.train)

summary(custom.log)
#vif(custom.log)
cat("**********************************************\n**********************************************\n\n")
fit.pred.custom <- predict(custom.log, newdata = BankAF.test, type= "response")

p = data.frame(Subs = BankAF.test$Subscription, Preds = fit.pred.custom)
names(p)[2] <- 'Preds'
p %>% group_by(Subs, Preds) %>% ggplot(aes(x = Preds, fill = Subs)) + geom_boxplot() + facet_grid(rows = p$Subs)
p %>% group_by(Subs, Preds) %>% ggplot(aes(x = Preds, fill = Subs)) + geom_histogram(binwidth = 0.01) + facet_grid(rows = p$Subs)
p.no = p %>% group_by(Subs, Preds) %>% subset(Subs == "no")
p.yes = p %>% group_by(Subs, Preds) %>% subset(Subs == "yes")
summary(p.no)
summary(p.yes)

cutoff.custom = 0.545

# Lets see how we did
results.custom <- prediction(fit.pred.custom,BankAF.test$Subscription,label.ordering=c("no","yes"))

class.custom <- factor(ifelse(fit.pred.custom >= cutoff.custom, 'yes','no'),levels = c('no','yes'))

roc.custom=performance(results.custom,measure = "tnr", x.measure = "fnr")

print("Confusion Custom")
CM = confusionMatrix(class.custom, BankAF.test$Subscription)
CM$table
CM$overall[1]
CM$byClass[1]
CM$byClass[2]

# residuals
plot(custom.log)
```

# Lasso Model
```{r}
# Build Lasso Model on train set 74/72
Bank.Train.x <- model.matrix(Subscription ~ ., BankAF.train[,-c(5,22)])
Bank.Train.y <- BankAF.train[,21]

cvfit <- cv.glmnet(Bank.Train.x, Bank.Train.y, family = "binomial", type.measure = "class", nlambda = 1000)

plot(cvfit)
coef(cvfit, s = "lambda.min")

# Cv Missclassification
print("Cv Error Rate:")
cvfit$cvm[which(cvfit$lambda==cvfit$lambda.min)]


# Optimal Penalty
print("Penalty Value:")
cvfit$lambda.min

# Final Model
finalmodel <- glmnet(Bank.Train.x, Bank.Train.y, family = "binomial", lambda = cvfit$lambda.min)

# Get predictions from Lasso Model on Test set
Bank.Test.x <- model.matrix(Subscription ~ ., BankAF.test[,-c(5,22)])

fit.pred.lasso <- predict(finalmodel, newx = Bank.Test.x, type = "response")

p = data.frame(Subs = BankAF.test$Subscription, Preds = fit.pred.lasso)
names(p)[2] <- 'Preds'
p %>% group_by(Subs, Preds) %>% ggplot(aes(x = Preds, fill = Subs)) + geom_boxplot() + facet_grid(rows = p$Subs)

p.no = p %>% group_by(Subs, Preds) %>% subset(Subs == "no")
summary(p.no)
coef(finalmodel)
# Set Cutoff
cutoff.lasso <- 0.38

class.lasso <- factor(ifelse(fit.pred.lasso > cutoff.lasso, 'yes','no'),levels = c('no','yes'))

print("Confusion Lasso")
confusionMatrix(class.lasso, BankAF.test$Subscription)
```

```{r}
# Temp training and test sets to play with
Bank.Temp.train <- BankAF.train %>% mutate(scaleEmp = scale(emp.var.rate, scale = FALSE)) %>% mutate(scaleNR = scale(nr.employed, scale = FALSE))
Bank.Temp.test <- BankAF.test %>% mutate(scaleEmp = scale(emp.var.rate, scale = FALSE)) %>% mutate(scaleNR = scale(nr.employed, scale = FALSE))
rm(Bank.Temp.test, Bank.Temp.train)
```


# Answer to Question 1
```{r}
# Custom Block - copy 72/72.5

cutoff.simple <- 0.54

simple.log<-glm(Subscription ~ duration + nr.employed + emp.var.rate + cons.price.idx + poutcome + month + job,
                family="binomial",data=BankAF.train)
summary(simple.log)

#confint(simple.log, "month", 0.95)

vif(simple.log)
fit.pred.simple <- predict(simple.log,newdata=BankAF.test,type="response")

results.simple <- prediction(fit.pred.simple,BankAF.test$Subscription,label.ordering=c("no","yes"))

class.simple <- factor(ifelse(fit.pred.simple > cutoff.simple, 'yes','no'),levels = c('no','yes'))

p = data.frame(Subs = BankAF.test$Subscription, Preds = fit.pred.simple)
names(p)[2] <- 'Preds'
p %>% group_by(Subs, Preds) %>% ggplot(aes(x = Preds, fill = Subs)) + geom_boxplot() + facet_grid(rows = p$Subs)

p.no = p %>% subset(Subs == "no")
summary(p.no)

print("Confusion Simple")
CM = confusionMatrix(class.simple, BankAF.test$Subscription)
sprintf("Cutoff = %s", cutoff.simple)
CM$table
CM$overall[1]
CM$byClass[1]
CM$byClass[2]
roc.simple=performance(results.simple,measure = "tnr", x.measure = "fnr")

# Residuals
plot(simple.log)
```

```{r}
# Cut off Finder - found the need to go all the way to 1
CM.Acc <- c()
CM.Sens <- c()
CM.Spec <- c()
index <- 1:2000/2000
for (i in index){
  
  class.simple <- factor(ifelse(fit.pred.simple > i, 'yes','no'),levels = c('no','yes'))
  CM = confusionMatrix(class.simple, BankAF.test$Subscription)
 
  CM.Acc <- c(CM.Acc,(CM$table[1,2] + CM$table[2,1])/sum(CM$table))
  CM.Sens <- c(CM.Sens,CM$table[2,1]/(CM$table[2,1] + CM$table[1,1]))
  CM.Spec <- c(CM.Spec,CM$table[1,2]/(CM$table[1,2] + CM$table[2,2]))
}

plot(index,CM.Acc,type="l",col="black",ylab="Percent",xlab="Threshold for predicting Yes",ylim=c(0,1),lwd=2,main = "Interactions - With Duration")
lines(index,CM.Sens,lty=3,col="orange",lwd=2)
lines(index,CM.Spec,lty=5,col="blue",lwd=2)
abline(v = .54, col = "darkorchid4")
legend("top",legend=c("ME","FP","FN"),col=c("black","orange","blue"),lty=1,lwd=1)

```

```{r}
# Creating step log model with PCs -  this didnt very well

# Creates a numeric data set for PCA
BankAF.Numeric<- BankAF %>% dplyr::select(age, campaign,pdays, previous, emp.var.rate, cons.price.idx, cons.conf.idx, euribor3m, nr.employed, SubNum)

# Create Train and test Samples
BankAF.Numeric.yes <- subset(BankAF.Numeric, SubNum == 1)
BankAF.Numeric.no <- subset(BankAF.Numeric, SubNum == 0)

set.seed(35)
index.yes<-sample(1:dim(BankAF.Numeric.yes)[1],DimYes,replace=F)
train.yes<-BankAF.Numeric.yes[index.yes,]
test.yes<-BankAF.Numeric.yes[-index.yes,]

index.no<-sample(1:dim(BankAF.Numeric.no)[1],DimNo,replace=F)
train.no<-BankAF.Numeric.no[index.no,]
test.no<-BankAF.Numeric.no[-index.no,]

BankAF.train.x <- rbind(train.no, train.yes)
BankAF.train.y <- BankAF.train.x[,10]
BankAF.train.y <- as.factor(as.character(BankAF.train.y))
BankAF.train.x <- BankAF.train.x[,1:9]


BankAF.test.x <- rbind(test.no, test.yes)
BankAF.test.y <- BankAF.test.x[,10]
BankAF.test.y <- as.factor(as.character(BankAF.test.y))
BankAF.test.x <- BankAF.test.x[,1:9]

# remove intermediate data sets
rm(test.no, test.yes, train.no, train.yes, BankAF.Numeric.no, BankAF.Numeric.yes)

# Creating PC Train Set
pc.result <- prcomp(BankAF.train.x, scale. = TRUE)
pc.scores <- pc.result$x
pc.scores <- data.frame(pc.scores)
pc.scores$SubNum <- BankAF.train.y

pc.result$rotation


# Create PC test Set
pc.result.test <- prcomp(BankAF.test.x, scale = TRUE)
pc.scores.test <- pc.result.test$x
pc.scores.test <- data.frame(pc.scores.test)


pc.log.full <- glm(SubNum ~ ., family = 'binomial', data = pc.scores)
pc.step.log <- pc.log.full %>% stepAIC(trace = FALSE)


cutoff.pc = 0.4

fit.pc.log <- predict(pc.step.log, newdata = pc.scores.test, type = "response")

results.pc.log <- prediction(fit.pc.log, BankAF.test.y, label.ordering = c("0", "1"))

class.pc.log <- factor(ifelse(fit.pc.log > cutoff.pc, "1", "0"), levels = c("0", "1"))

p = data.frame(Subs = BankAF.test$Subscription, Preds = fit.pc.log)
names(p)[2] <- 'Preds'
p %>% group_by(Subs, Preds) %>% ggplot(aes(x = Preds, fill = Subs)) + geom_boxplot() + facet_grid(rows = p$Subs)

print("Confusion Matrix PC")
confusionMatrix(class.pc.log, BankAF.test.y)

roc.pc = performance(results.pc.log,measure = "tnr", x.measure = "fnr")
```


```{r}

# Get results from predictions
results.lasso <- prediction(fit.pred.lasso, BankAF.test$Subscription,label.ordering=c("no","yes"))
results.step <- prediction(fit.pred.step, BankAF.test$Subscription,label.ordering=c("no","yes")) 

# look at performance metrics of above predictions
roc.lasso = performance(results.lasso, measure = "tnr", x.measure = "fnr")
roc.step = performance(results.step, measure = "tnr", x.measure = 'fnr')

plot(roc.lasso, col = "red", lty = 1, main = "ROC Question 1 - Without Duration")
plot(roc.step, col = "blue1", lty = 2, add = TRUE)
plot(roc.simple, col = "darkgreen", lty = 3, add = TRUE)
#plot(roc.custom, col = "darkorchid4", lty = 4, add = TRUE)
abline(a=0, b= 1)
legend("bottomright",legend=c("Lasso","Stepwise","Simple"),col=c("red","blue","green"),lty=1,lwd=1)

```
Function for categorizing continuous variable into vector of categories
```{r}
bin=function(residNorm,numBins=5)
{
  rangeResid=range(residNorm)[2]-range(residNorm)[1]
  # we want equally spaced numbbers from start to end if we wanted 3 bins... & range of 30
  # we would identify interval space first, 30/numbins = 10
  interval=rangeResid/(numBins)
  binLimits=seq(range(residNorm)[1],range(residNorm)[2],interval)
  #sort the resids and put the resid labelled as the binLimit that is right before the
  #residNorm=residNorm[order(residNorm)]
  binArray=double(length(residNorm))
  #for each residNorm find the maximum binLimits it is greater than and assign it that limit
  for(i in 1:length(binArray)){
    res=residNorm[i]
    binArray[i]=ifelse(max(binLimits[which(binLimits<res)])==-Inf,binLimits[1],
                       max(binLimits[which(binLimits<res)]))
  }
  binArray = binArray + (interval/2)
  return(binArray)
}
```


```{r}
simple.log<-glm(Subscription ~  nr.employed + emp.var.rate + cons.price.idx + poutcome + month ,
                family="binomial",data=BankAF.train)


BankAF.train['fitted.values'] = simple.log$fitted.values
prob_bin=bin(BankAF.train$fitted.values,10000)
BankAF.train['predicted_bin']=prob_bin
BankAF.train %>% group_by(predicted_bin) %>%
  summarise(prob_yes=mean(Subscription=='yes'),num_obs=n()) %>%
  ggplot() +
  geom_point(aes(predicted_bin,prob_yes-predicted_bin,size=num_obs))+
  ylab('Residual (Actual Prob - Predicted Prob)')+
  xlab('Predicted Probability')+
  geom_text(aes(predicted_bin,prob_yes-predicted_bin,size=num_obs,label='a'))


```
Delete the added columns
```{r}
BankAF.train=BankAF.train[,!(names(BankAF.train) %in% c('predicted_bin','fitted.values'))]
```










